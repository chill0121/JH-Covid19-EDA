---
title: "Johns Hopkins' Covid-19 Data EDA"
author: "Cody Hill"
date: "2023-04-25"
output:
  pdf_document: default
  html_document: default
---

## Setup
***

Note, before using knitr please install all missing packages from the code cell below into your environment. 

Also, I recommended knitting into HTML as it has been optimized for viewing in that format.

### Data Source Information

**"COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University"**

This data was procured from <https://github.com/CSSEGISandData/COVID-19> which is a github repository where Johns Hopkins compiled covid-19 data. This repository stopped updating on 3/10/23.
In this report we are specifically looking at the `./csse_covid_19_data/csse_covid_19_time_series` data.

I encourage all who reads this report to go read the `readme.md` file in the source's repository to gain more insights about where this data was collected, how it was validated, and compiled into this dataset.
In short, the US data was collected from individual state and county Departments of Health and the global data was collected from various government bodies within each country (with a few exceptions).

*This data set is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) by the Johns Hopkins University on behalf of its Center for Systems Science in Engineering. Copyright Johns Hopkins University 2020.*

#### Feature Descriptions from Source

- **FIPS:** US only. Federal Information Processing Standards code that uniquely identifies counties within the USA.
- **Admin2:** County name. US only.
- **Province_State:** Province, state or dependency name.
- **Country_Region:** Country, region or sovereignty name. The names of locations included on the Website correspond with the official designations used by the U.S. Department of State.
- **Lat and Long_:** Dot locations on the dashboard. All points (except for Australia) shown on the map are based on geographic centroids, and are not representative of a specific address, building or any location at a spatial scale finer than a province/state. Australian dots are located at the centroid of the largest city in each state.
- **Cases:** Counts include confirmed and probable (where reported).
- **Deaths:** Counts include confirmed and probable (where reported).
- **UID:** Unique Identifier for each row entry.
- **ISO3:** Officially assigned country code identifiers.

### Environment Setup

First we will import the libraries in R that are needed.

Then, we will import the data using a URL directly from the source, this means it will update anytime we reknit.

```{r Setup RMD}
# Output all commands run and set a standard plot size
knitr::opts_chunk$set(echo = TRUE, fig.width = 10, fig.height = 6)
# Import Libraries
library(tidyverse)
library(lubridate)
library(ggplot2)
library(ggmap)
library(gridExtra)
# Import dataset
us_cases <- read.csv("https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
us_deaths <- read.csv("https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")
global_cases <- read.csv("https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv")
global_deaths <- read.csv("https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv")
```

## Initial Look at the Data
***

Let's look at the data in its raw form to decide what to do with it.

```{r First Look}
dim(us_cases)
dim(us_deaths)
dim(global_cases)
dim(global_deaths)

head(us_deaths[1:14])
head(global_deaths[1:6])
```

*I'm slicing the output so we don't see the date columns as they will fill the screen.*
Here we can see each date is in an individual column **(feature)**, also `us_deaths` has an extra feature named `Population`.

Also, interesting to see reporting started on January, 22, 2020.

## Cleaning and Transformation Stage
***

To clean up these datasets we will do the following,

US Data:

- Pivot the date columns into rows
- Merge the cases and deaths datasets, keeping population

Global Data:

- Pivot the date columns into rows
- Merge the cases and death datasets
- Import population data for each country and add a population column

Also in both datasets,

- Remove redundant features and several that we won't be using
- Rename a few features for consistency and readability
- Transform feature class types for easier analysis
- Check for duplicates and missing entries, NA, Null etc.

### Cleaning US Datasets

```{r Cleaning US Data}
# US_Deaths transformations
us_deaths <- us_deaths %>%
    # Pivot all the date columns
    pivot_longer(., -c('UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State', 'Country_Region', 'Lat', 'Long_', 'Combined_Key', 'Population'),
        names_to = 'Date',
        values_to = 'Deaths') %>%
    # Remove unnecessary features
    select(., -iso2, -iso3, -code3, -FIPS, -Combined_Key) %>%
    # Rename some features
    rename(., County = 'Admin2',
        Long = 'Long_')

# US_Cases transformations
us_cases <- us_cases %>%
    # Pivot all the date columns
    pivot_longer(., -c('UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State', 'Country_Region', 'Lat', 'Long_', 'Combined_Key'),
        names_to = 'Date',
        values_to = 'Cases') %>%
    # Remove unnecessary features
    select(., -iso2, -iso3, -code3, -FIPS, -Combined_Key) %>%
    # Rename some features
    rename(., County = 'Admin2',
        Long = 'Long_')

# Merge into one dataframe
us_data <- full_join(us_cases, us_deaths)

# Remove the X in the dates and mutate to Date class
us_data$Date <- gsub('X', '', as.character(us_data$Date))
us_data <- us_data %>%
    mutate(Date = mdy(Date))

# Change character classes and UID into factors
us_data <- us_data %>%
        mutate(across(where(is.character), as.factor)) %>%
        mutate(UID = as.factor(UID))

# Display changes
head(us_data)
```

This will be much easier to work with.

### Cleaning US Datasets

Now let's do a similar procedure with the global data.

```{r Cleaning Global Data}
# Global_deaths transformations
global_deaths <- global_deaths %>%
    # Pivot all the date columns
    pivot_longer(., -c('Province.State', 'Country.Region', 'Lat', 'Long'),
        names_to = 'Date',
        values_to = 'Deaths') %>%
    # Rename some features
    rename(., Province_State = 'Province.State',
        Country_Region = 'Country.Region')

# Global_Cases transformations
global_cases <- global_cases %>%
    # Pivot all the date columns
    pivot_longer(., -c('Province.State', 'Country.Region', 'Lat', 'Long'),
        names_to = 'Date',
        values_to = 'Cases') %>%
    # Rename some features
    rename(., Province_State = 'Province.State',
        Country_Region = 'Country.Region')

# Merge into one dataframe
global_data <- full_join(global_cases, global_deaths)

# Remove the X in the dates and mutate to Date class
global_data$Date <- gsub('X', '', as.character(global_data$Date))
global_data <- global_data %>%
    mutate(Date = mdy(Date))

# Display changes
head(global_data)
```

Now because we might be interested in making some per capita comparisons in the future, let's import population data and add it to each country in `global_data`.

```{r Import Population to Global}
# Import Table with Populations
UID_Table <- read.csv('https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv')
head(UID_Table)
# Merge population in using left_join
global_data <- global_data %>%
    left_join(UID_Table, by = c('Province_State', 'Country_Region', 'Lat')) %>%
    select(-c(UID, iso2, iso3, code3, FIPS, Admin2, Combined_Key, Long_))

# Change character classes into factors
global_data <- global_data %>%
        mutate(across(where(is.character), as.factor))
```

Finally, we should take a look at a summary of our two datasets and see if we can make any high level conclusions.

```{r Summary}
summary(us_data)
summary(global_data)
```

Even with just this we can determine several things:

- This data goes from 2020/01/22 to 2023/03/09
- The distribution of cases is heavily right-skewed (positively skewed) which makes sense considering there are more countries with low populations when compared to large countries pushing the mean towards the right. Also, it's a cumulative sum.
- This dataset tracks a high granularity of countries, given the minimum population is 67.

Looks like there are a few issues here as well:

- In the US data the minimum of `Cases` and `Deaths` is showing a negative value
- In the global data there are NAs in `Lat` and `Long`
- In the global data there are NAs in `Population`

We can look at these in order.
```{r Negative Cases and Deaths}
filter(us_data, Cases < 0 | Deaths < 0)
```

Looks to be all from the same 3 entries. Not a significant amount of data, easiest to just drop the rows in this case.
Also, since cases and deaths are cumulative sums (rolling total) we aren't missing much if we do drop them (i.e. we will likely pick up whatever these were intended to be in the next valid entry).

```{r Drop Negatives}
# Before
dim(us_data)
# Remove bad entries
us_data <- us_data[us_data$Cases >= 0 | us_data$Deaths >= 0, ]
# After
dim(us_data)
```

We can see here that we've successfully removed the 3 bad entries.

Now for the coordinate data NAs.
```{r Lat and Long NAs}
lat_na = (filter(global_data, global_data$Lat == is.na(Lat)))
unique(lat_na$Province_State)
```

Interesting, this dataset includes the cruise ships that were quarantined for Covid-19 outbreaks. 
It makes sense there there isn't coordinate data to go along with these entries. We will leave them alone.

Now for the population data NAs.
```{r, Population NAs 1, results = 'hide'}
# Find index of NAs
which(is.na(global_data$Population))
```
*Output hidden here because it's too long.*
```{r Population NAs 2}
# Display a few NA examples
global_data[5716,]
global_data[326898,]
global_data[121222,]
```

This also looks fine, Antarctica and the 2022 Winter Olympics are certainly interesting entries but won't necessarily have a population associated.
We will leave these as well and just be mindful of these entries when we do our analysis.

## Visualizations
***

With the cleaning and transformation of the data complete, let's begin plotting some of these to get
a better sense of the data and hopefully tease out some conclusions.

### Global Data

First I think it'd be useful to plot the cases and deaths per capita (1 million) per country, scaling our data to population size which normalizes comparisons between countries.

We'll only display the top 50 since there are 201 `Countries_Regions`.
```{r Cases and Deaths Per Capita}
# Group by Country, and max population (since cases and deaths are cumulative we don't sum)
# Note na.rm = TRUE because otherwise R will throw a max of NA if one is in the set
country_totals <- global_data %>%
    group_by(Country_Region) %>%
    summarize(Cases = max(Cases, na.rm = TRUE),
        Deaths = max(Deaths, na.rm = TRUE),
        Population = max(Population, na.rm = TRUE),
        Lat = median(Lat, na.rm = TRUE),
        Long = median(Long, na.rm = TRUE),
        Cases_Per_Million = max(Cases, na.rm = TRUE) / (max(Population, na.rm = TRUE) / 100000),
        Deaths_Per_Million = max(Deaths, na.rm = TRUE) / (max(Population, na.rm = TRUE) / 100000),
        Deaths_Per_Case = max(Deaths, na.rm = TRUE) / max(Cases, na.rm = TRUE))

# Sort by per capita in descending order and order the factors for graph order
country_pc_cases <- arrange(country_totals, desc(country_totals$Cases_Per_Million))
country_pc_cases$Country_Region <- fct_inorder(country_pc_cases$Country_Region)

country_pc_deaths <- arrange(country_totals, desc(country_totals$Deaths_Per_Million))
country_pc_deaths$Country_Region <- fct_inorder(country_pc_deaths$Country_Region)

country_pc_cases_plot <- country_pc_cases[1:50, ] %>%
   ggplot(., aes(x = Country_Region, y = Cases_Per_Million, fill = Country_Region)) + 
   geom_bar(stat = 'identity', show.legend = FALSE) +
   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
   labs(title = 'Covid-19 Cases Per Million by Country as of March 9, 2023',
        x = 'Country / Region', y = 'Covid-19 Cases per Million',
        caption = 'Source:<https://github.com/CSSEGISandData/COVID-19>')

country_pc_deaths_plot <- country_pc_deaths[1:50, ] %>%
   ggplot(., aes(x = Country_Region, y = Deaths_Per_Million, fill = Country_Region)) + 
   geom_bar(stat = 'identity', show.legend = FALSE) +
   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
   labs(title = 'Covid-19 Deaths Per Million by Country as of March 9, 2023',
        x = 'Country / Region', y = 'Covid-19 Deaths per Million',
        caption = 'Source:<https://github.com/CSSEGISandData/COVID-19>')

country_pc_cases_plot
country_pc_deaths_plot
```

As you can see there is a significant difference between which countries rank high in total number of cases versus total number of deaths.
This could be because of a number of reasons; 1: Access to healthcare, 2: Vaccine roll-out differences, 3: Covid-19 reporting differences, and so on.

For instance:

- Peru leads the mortality rate but is not in the top 50 of number cases. That tells us that Peruvians who got Covid-19 had a higher probability of succumbing to the disease. *(Note: we are not claiming a cause here.)*
- Austria while number 2 in total cases is low in deaths in this top 50 list.
- San Marino, while a small country, reports ~ 2/3 of their population in total number of cases.
- Iceland and South Korea both place high in number of total cases but don't top 50 in deaths.

This leads me to wonder what the distribution of countries might look like if we graph $Total Deaths / Total Cases$. This would give us the ratio of people who
died per case, giving us an interesting perspective about how each country/region responded to Covid-19.

```{r Deaths per Case Ratio}
country_deaths_per_case <- arrange(country_totals, desc(country_totals$Deaths_Per_Case))
country_deaths_per_case$Country_Region <- fct_inorder(country_deaths_per_case$Country_Region)

# Mutate North Korea to fit on graph for easier viewing of others
country_deaths_per_case <- country_deaths_per_case %>%
        mutate(Deaths_Per_Case = ifelse(Deaths_Per_Case > 0.5, 0.5, Deaths_Per_Case))

country_deaths_per_case_plot <- country_deaths_per_case[1:50, ] %>%
   ggplot(., aes(x = Country_Region, y = Deaths_Per_Case, fill = Country_Region)) + 
   geom_bar(stat = 'identity', show.legend = FALSE) +
   ylim(0, 0.5) +
   annotate('label', x = 6, y = 0.4, angle = 90, color = '#f92f07', label = 'North Korea = 6.0') +
   annotate('label', x = 7, y = 0.37, angle = 90, color = '#f92f07', label = 'Cropped for Clarity') +
   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
   labs(title = 'Percentage of Deaths per Case of Covid-19 by Country as of March 9, 2023',
        x = 'Country / Region', y = 'Covid-19 Deaths per Cases',
        caption = 'Source:<https://github.com/CSSEGISandData/COVID-19>')

country_deaths_per_case_plot
```
*Note: North Korea was changed to fit in this graph for easier viewing of the remaining data. N.Korea = 6.0*

- According to this data you have a 600% chance of dying if you caught Covid-19 in North Korea. Looking into this further we see they reported 6 deaths and 1 case, obviously not a reliable source for North Korea Covid-19 data.
- MS Zaandam was a cruise ship with unfortunate timing undocking in March 2020 where 9 cases would develop resulting in 2 deaths.
- Yemen had a very high mortality rate.
- Further on we see Peru near the top which confirms our previous hypothesis when looking at total number of deaths, they struggled with Covid-19.

### US Data

Let's utilize the `Lat` and `Long` coordinates to graph our data on a map of the US.

```{r US Map}
```